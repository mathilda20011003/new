#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ”¹è¿›åçš„AIæ‘˜è¦æç¤ºè¯æ•ˆæœ
"""

import os
import requests
import feedparser
from dotenv import load_dotenv

def test_improved_prompts():
    """æµ‹è¯•æ”¹è¿›åçš„æç¤ºè¯"""
    load_dotenv()
    
    print("ğŸ§ª æµ‹è¯•æ”¹è¿›åçš„AIæ‘˜è¦æç¤ºè¯...")
    
    # è·å–çœŸå®æ–‡ç« è¿›è¡Œæµ‹è¯•
    base_url = os.getenv('WEWE_RSS_BASE_URL', 'https://ssys2025.zeabur.app')
    test_feed_id = "MP_WXS_3073282833"  # æœºå™¨ä¹‹å¿ƒ
    
    try:
        response = requests.get(f"{base_url}/feeds/{test_feed_id}", timeout=10)
        
        if response.status_code == 200:
            feed = feedparser.parse(response.content)
            
            if feed.entries:
                # æµ‹è¯•å‰3ç¯‡æ–‡ç« 
                for i, entry in enumerate(feed.entries[:3], 1):
                    print(f"\n{'='*60}")
                    print(f"ğŸ“° æµ‹è¯•æ–‡ç«  {i}: {entry.get('title', 'æ— æ ‡é¢˜')}")
                    print(f"{'='*60}")
                    
                    article_url = entry.get('link', '')
                    article_title = entry.get('title', 'æ— æ ‡é¢˜')
                    
                    if article_url:
                        test_single_article(article_url, article_title)
                    else:
                        print("âŒ æœªæ‰¾åˆ°æ–‡ç« é“¾æ¥")
            else:
                print("âŒ RSSä¸­æ²¡æœ‰æ–‡ç« ")
        else:
            print(f"âŒ RSSè·å–å¤±è´¥: {response.status_code}")
            
    except Exception as e:
        print(f"âŒ RSSè·å–å¼‚å¸¸: {e}")

def test_single_article(url, title):
    """æµ‹è¯•å•ç¯‡æ–‡ç« çš„æ‘˜è¦ç”Ÿæˆ"""
    try:
        # 1. è·å–æ–‡ç« å†…å®¹
        from wechat_rss.content_fetcher import WeChatContentFetcher
        
        fetcher = WeChatContentFetcher(timeout=15, retry_times=2)
        content_data = fetcher.fetch_article_content(url)
        
        if not content_data:
            print("âŒ æ— æ³•è·å–æ–‡ç« å†…å®¹")
            return
        
        content = content_data['content']
        print(f"ğŸ“ æ–‡ç« å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        print(f"ğŸ“„ å†…å®¹é¢„è§ˆ: {content[:200]}...")
        
        # 2. æµ‹è¯•æ–°çš„AIæ‘˜è¦
        test_new_summarizer(title, content)
        
    except Exception as e:
        print(f"âŒ æ–‡ç« å¤„ç†å¤±è´¥: {e}")

def test_new_summarizer(title, content):
    """æµ‹è¯•æ–°çš„æ‘˜è¦ç”Ÿæˆå™¨"""
    try:
        from wechat_rss.ai_summarizer import AISummarizer
        
        api_key = os.getenv('OPENROUTER_API_KEY')
        model = os.getenv('AI_MODEL', 'google/gemini-2.5-flash-lite-preview-09-2025')
        
        if not api_key:
            print("âš ï¸ æœªé…ç½®OpenRouter APIå¯†é’¥ï¼Œè·³è¿‡AIæ‘˜è¦æµ‹è¯•")
            return
        
        print(f"\nğŸ¤– ä½¿ç”¨æ”¹è¿›åçš„æç¤ºè¯ç”Ÿæˆæ‘˜è¦...")
        
        # åˆ›å»ºæ‘˜è¦ç”Ÿæˆå™¨
        summarizer = AISummarizer(
            provider='openrouter',
            api_key=api_key,
            model=model,
            max_tokens=200  # å¢åŠ tokenæ•°é‡ä»¥æ”¯æŒæ›´é•¿çš„æ‘˜è¦
        )
        
        # ç”Ÿæˆæ‘˜è¦
        summary = summarizer.summarize(title, content)
        
        if summary:
            print(f"âœ… æ–°æ‘˜è¦ç”ŸæˆæˆåŠŸ:")
            print(f"ğŸ’¡ æ‘˜è¦å†…å®¹: {summary}")
            
            # åˆ†ææ‘˜è¦è´¨é‡
            analyze_summary_quality(summary, title, content)
        else:
            print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æ‘˜è¦æµ‹è¯•å¤±è´¥: {e}")

def analyze_summary_quality(summary, title, content):
    """åˆ†ææ‘˜è¦è´¨é‡"""
    print(f"\nğŸ“Š æ‘˜è¦è´¨é‡åˆ†æ:")
    
    # 1. é•¿åº¦åˆ†æ
    summary_length = len(summary)
    if summary_length < 50:
        print(f"âš ï¸ æ‘˜è¦åçŸ­ ({summary_length} å­—ç¬¦)")
    elif summary_length > 150:
        print(f"âš ï¸ æ‘˜è¦åé•¿ ({summary_length} å­—ç¬¦)")
    else:
        print(f"âœ… æ‘˜è¦é•¿åº¦é€‚ä¸­ ({summary_length} å­—ç¬¦)")
    
    # 2. å†…å®¹è´¨é‡åˆ†æ
    quality_indicators = {
        "ä¸“ä¸šæœ¯è¯­": check_professional_terms(summary),
        "å…·ä½“æ•°æ®": check_specific_data(summary),
        "åˆ†ææ·±åº¦": check_analysis_depth(summary),
        "å•†ä¸šæ´å¯Ÿ": check_business_insight(summary),
        "é¿å…é‡å¤": not check_title_repetition(summary, title)
    }
    
    print(f"ğŸ“ˆ è´¨é‡æŒ‡æ ‡:")
    for indicator, passed in quality_indicators.items():
        status = "âœ…" if passed else "âš ï¸"
        print(f"   {status} {indicator}: {'é€šè¿‡' if passed else 'éœ€æ”¹è¿›'}")
    
    # 3. æ•´ä½“è¯„åˆ†
    score = sum(quality_indicators.values()) / len(quality_indicators) * 100
    print(f"ğŸ¯ æ•´ä½“è´¨é‡è¯„åˆ†: {score:.1f}%")
    
    if score >= 80:
        print(f"ğŸ‰ æ‘˜è¦è´¨é‡ä¼˜ç§€ï¼")
    elif score >= 60:
        print(f"ğŸ‘ æ‘˜è¦è´¨é‡è‰¯å¥½")
    else:
        print(f"ğŸ”§ æ‘˜è¦è´¨é‡éœ€è¦æ”¹è¿›")

def check_professional_terms(summary):
    """æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸“ä¸šæœ¯è¯­"""
    professional_terms = [
        "æŠ€æœ¯", "åˆ›æ–°", "çªç ´", "ä¼˜åŒ–", "æå‡", "è§£å†³æ–¹æ¡ˆ", "å¹³å°", "ç³»ç»Ÿ",
        "æ¨¡å‹", "ç®—æ³•", "æ¡†æ¶", "å·¥å…·", "åº”ç”¨", "åœºæ™¯", "ä»·å€¼", "å½±å“",
        "å¸‚åœº", "è¡Œä¸š", "ç«äº‰", "ä¼˜åŠ¿", "æœºä¼š", "è¶‹åŠ¿", "å‘å±•", "å¢é•¿"
    ]
    return any(term in summary for term in professional_terms)

def check_specific_data(summary):
    """æ£€æŸ¥æ˜¯å¦åŒ…å«å…·ä½“æ•°æ®æˆ–äº‹å®"""
    import re
    # æ£€æŸ¥æ•°å­—ã€ç™¾åˆ†æ¯”ã€å…·ä½“åç§°ç­‰
    patterns = [
        r'\d+',  # æ•°å­—
        r'\d+%',  # ç™¾åˆ†æ¯”
        r'\d+äº¿',  # äº¿çº§æ•°æ®
        r'\d+ä¸‡',  # ä¸‡çº§æ•°æ®
        r'[A-Z][a-zA-Z]+',  # è‹±æ–‡åç§°/å“ç‰Œ
    ]
    return any(re.search(pattern, summary) for pattern in patterns)

def check_analysis_depth(summary):
    """æ£€æŸ¥åˆ†ææ·±åº¦"""
    depth_indicators = [
        "åˆ†æ", "è¯„ä¼°", "é¢„æµ‹", "å½±å“", "æ„ä¹‰", "ä»·å€¼", "ä¼˜åŠ¿", "æŒ‘æˆ˜",
        "æœºä¼š", "è¶‹åŠ¿", "å˜åŒ–", "å‘å±•", "æå‡", "æ”¹è¿›", "çªç ´", "åˆ›æ–°"
    ]
    return any(indicator in summary for indicator in depth_indicators)

def check_business_insight(summary):
    """æ£€æŸ¥å•†ä¸šæ´å¯Ÿ"""
    business_terms = [
        "å•†ä¸š", "å¸‚åœº", "ç«äº‰", "ä¼˜åŠ¿", "æœºä¼š", "ä»·å€¼", "æ”¶ç›Š", "æ•ˆç‡",
        "æˆæœ¬", "æŠ•èµ„", "å›æŠ¥", "å¢é•¿", "è§„æ¨¡", "ä»½é¢", "é¢†å…ˆ", "å¸ƒå±€"
    ]
    return any(term in summary for term in business_terms)

def check_title_repetition(summary, title):
    """æ£€æŸ¥æ˜¯å¦ç®€å•é‡å¤æ ‡é¢˜"""
    # å¦‚æœæ‘˜è¦ä¸­åŒ…å«æ ‡é¢˜çš„å¤§éƒ¨åˆ†å†…å®¹ï¼Œè®¤ä¸ºæ˜¯é‡å¤
    title_words = set(title.replace('ï¼Œ', '').replace('ã€‚', '').replace('ï¼', '').replace('ï¼Ÿ', ''))
    summary_words = set(summary.replace('ï¼Œ', '').replace('ã€‚', '').replace('ï¼', '').replace('ï¼Ÿ', ''))
    
    if len(title_words) == 0:
        return False
    
    overlap_ratio = len(title_words & summary_words) / len(title_words)
    return overlap_ratio > 0.7  # å¦‚æœé‡å åº¦è¶…è¿‡70%ï¼Œè®¤ä¸ºæ˜¯é‡å¤

def compare_with_old_prompts():
    """å¯¹æ¯”æ–°æ—§æç¤ºè¯æ•ˆæœ"""
    print(f"\nğŸ”„ å¯¹æ¯”æ–°æ—§æç¤ºè¯æ•ˆæœ...")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ å¯¹æ¯”æµ‹è¯•çš„é€»è¾‘
    # ç”±äºæ—§ç‰ˆæœ¬å·²ç»è¢«æ›¿æ¢ï¼Œè¿™é‡Œä¸»è¦æ˜¯å±•ç¤ºæ¦‚å¿µ
    
    print(f"ğŸ“Š é¢„æœŸæ”¹è¿›:")
    print(f"   âœ… æ‘˜è¦é•¿åº¦: 50-80å­— â†’ 80-120å­—")
    print(f"   âœ… åˆ†ææ·±åº¦: ç®€å•æ€»ç»“ â†’ ä¸“ä¸šæ´å¯Ÿ")
    print(f"   âœ… å†…å®¹ç±»å‹: é€šç”¨æ¨¡æ¿ â†’ åˆ†ç±»ä¼˜åŒ–")
    print(f"   âœ… ä¸“ä¸šç¨‹åº¦: åŸºç¡€æè¿° â†’ å•†ä¸šåˆ†æ")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ”¹è¿›åçš„AIæ‘˜è¦æç¤ºè¯\n")
    
    # æµ‹è¯•æ”¹è¿›åçš„æç¤ºè¯
    test_improved_prompts()
    
    # å¯¹æ¯”åˆ†æ
    compare_with_old_prompts()
    
    print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ’¡ å¦‚æœæ‘˜è¦è´¨é‡æœ‰æ˜¾è‘—æå‡ï¼Œè¯´æ˜æ–°æç¤ºè¯ç”Ÿæ•ˆ")
    print(f"ğŸ”§ å¦‚æœè´¨é‡ä»éœ€æ”¹è¿›ï¼Œå¯ä»¥è¿›ä¸€æ­¥è°ƒæ•´æç¤ºè¯ç­–ç•¥")
