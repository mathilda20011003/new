#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import requests
import feedparser
from pathlib import Path
from datetime import datetime

# è®¾ç½®UTF-8ç¼–ç 
os.environ['PYTHONIOENCODING'] = 'utf-8'

print("ğŸš€ å¼€å§‹è¿è¡ŒçœŸå®çš„å¾®ä¿¡å…¬ä¼—å·RSSçˆ¬è™«...")

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')
sys.path.append('wechat_rss')

# åŠ è½½ç¯å¢ƒå˜é‡
def load_env():
    env_file = Path('.env')
    if env_file.exists():
        print("ğŸ“ åŠ è½½ .env æ–‡ä»¶...")
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()
        print("âœ… .env æ–‡ä»¶åŠ è½½å®Œæˆ")

def fetch_real_articles(feed_id, base_url, account_name):
    """è·å–çœŸå®çš„RSSæ–‡ç« """
    try:
        # å°è¯•ä¸åŒçš„RSS URLæ ¼å¼
        possible_urls = [
            f"{base_url}/rss/{feed_id}",
            f"{base_url}/rss/{feed_id}.atom",
            f"{base_url}/feed/{feed_id}",
            f"{base_url}/feed/{feed_id}.atom"
        ]

        rss_url = None
        response = None

        for url in possible_urls:
            try:
                print(f"ğŸ“¡ å°è¯•RSS: {url}")
                response = requests.get(url, timeout=10)
                if response.status_code == 200:
                    rss_url = url
                    print(f"âœ… RSSå¯ç”¨: {url}")
                    break
                else:
                    print(f"âŒ çŠ¶æ€ç : {response.status_code}")
            except Exception as e:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")

        if not rss_url or not response:
            raise Exception("æ‰€æœ‰RSS URLéƒ½ä¸å¯ç”¨")
        
        feed = feedparser.parse(response.content)
        articles = []
        
        print(f"ğŸ“‹ Feedæ ‡é¢˜: {feed.feed.get('title', 'æœªçŸ¥')}")
        print(f"ğŸ“Š æ€»æ–‡ç« æ•°: {len(feed.entries)}")
        
        for entry in feed.entries[:5]:  # å–å‰5ç¯‡
            article = {
                'title': entry.title,
                'link': entry.link,
                'published': entry.get('published', ''),
                'summary': entry.get('summary', ''),
                'account_name': account_name
            }
            articles.append(article)
            print(f"   ğŸ“° {entry.title[:50]}...")
            
        return articles
        
    except Exception as e:
        print(f"âŒ è·å–RSSå¤±è´¥: {e}")
        return []

def filter_by_keywords(articles, keywords):
    """å…³é”®è¯ç­›é€‰"""
    filtered = []
    for article in articles:
        title_content = f"{article['title']} {article['summary']}"
        if any(keyword in title_content for keyword in keywords):
            filtered.append(article)
            print(f"âœ… åŒ¹é…å…³é”®è¯: {article['title'][:50]}...")
        else:
            print(f"â­ï¸  è·³è¿‡: {article['title'][:50]}...")
    return filtered

def generate_ai_summary(content, title):
    """ç”ŸæˆAIæ‘˜è¦"""
    try:
        from wechat_rss.ai_summarizer import AISummarizer
        
        api_key = os.getenv('OPENROUTER_API_KEY')
        model = os.getenv('AI_MODEL', 'google/gemini-2.5-flash-lite-preview-09-2025')
        
        summarizer = AISummarizer(
            provider='openrouter',
            api_key=api_key,
            model=model,
            max_tokens=150
        )
        
        print(f"ğŸ¤– ç”ŸæˆAIæ‘˜è¦: {title[:30]}...")
        summary = summarizer.generate_summary(content, title)
        print(f"âœ… AIæ‘˜è¦å®Œæˆ")
        return summary
        
    except Exception as e:
        print(f"âŒ AIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
        return f"æ–‡ç« æ ‡é¢˜ï¼š{title}"

def send_to_feishu(articles):
    """å‘é€åˆ°é£ä¹¦"""
    try:
        webhook_url = os.getenv('FEISHU_WEBHOOK_URL')
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        text_content = []
        titles_list = []
        
        for article in articles:
            account_name = article['account_name']
            title = article['title']
            ai_summary = article['ai_summary']
            link = article['link']
            published = article['published']
            
            titles_list.append(f"{account_name}: {title}")
            
            # æ ¼å¼åŒ–æ—¶é—´
            try:
                from email.utils import parsedate_to_datetime
                dt = parsedate_to_datetime(published)
                pub_time = dt.strftime('%Y-%m-%d %H:%M:%S')
            except:
                pub_time = published or datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            # æ–°æ ¼å¼
            text_content.append(f"ğŸ“ {account_name}")
            text_content.append(f"ğŸ“° {title}")
            text_content.append(f"ğŸ’¡ {ai_summary}")
            text_content.append(f"ğŸ”— é˜…è¯»åŸæ–‡ | {pub_time}")
            text_content.append(f"   {link}")
            text_content.append("")
        
        message = {
            "content": {
                "report_type": "å¾®ä¿¡å…¬ä¼—å·AIæ‘˜è¦",
                "text": "\n".join(text_content),
                "total_titles": ", ".join(titles_list),
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        }
        
        print("ğŸ“¤ å‘é€åˆ°é£ä¹¦...")
        response = requests.post(
            webhook_url,
            json=message,
            headers={'Content-Type': 'application/json'},
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get('code') == 0:
                print("ğŸ‰ é£ä¹¦æ¨é€æˆåŠŸï¼")
                return True
        
        print(f"âŒ é£ä¹¦æ¨é€å¤±è´¥: {response.status_code}")
        return False
        
    except Exception as e:
        print(f"âŒ é£ä¹¦æ¨é€å¼‚å¸¸: {e}")
        return False

def main():
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_env()
    
    # é…ç½®
    base_url = os.getenv('WEWE_RSS_BASE_URL', 'https://ssys2025.zeabur.app').rstrip('/')
    
    # æµ‹è¯•å¤šä¸ªå…¬ä¼—å·ï¼Œæ¯ä¸ªç­›é€‰2ç¯‡
    test_accounts = [
        {
            'name': 'æœºå™¨ä¹‹å¿ƒ',
            'feed_id': 'MP_WXS_3073282833',
            'keywords': ['AI', 'å¤§æ¨¡å‹', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'æ¨¡å‹']
        },
        {
            'name': 'çŸ­å‰§è‡ªä¹ å®¤',
            'feed_id': 'MP_WXS_3906677264',
            'keywords': ['æ¼«å‰§', 'AIæ¼«å‰§', 'çŸ­å‰§', 'çº¢æœ', 'æ’­æ”¾é‡']
        },
        {
            'name': 'æ¼«å‰§æœ‰æ•°',
            'feed_id': 'MP_WXS_3621201576',
            'keywords': ['æ¼«å‰§', 'æŠ–éŸ³æ¼«å‰§', 'å¥³é¢‘', 'çˆ†æ¬¾', 'æ’­æ”¾']
        }
    ]
    
    all_filtered_articles = []

    # å¤„ç†æ¯ä¸ªå…¬ä¼—å·
    for test_account in test_accounts:
        print(f"\n{'='*60}")
        print(f"ğŸ“° å¤„ç†å…¬ä¼—å·: {test_account['name']}")
        print(f"   Feed ID: {test_account['feed_id']}")
        print(f"   å…³é”®è¯: {', '.join(test_account['keywords'])}")
        print(f"{'='*60}")

        # 1. è·å–æ–‡ç« 
        articles = fetch_real_articles(
            test_account['feed_id'],
            base_url,
            test_account['name']
        )

        if not articles:
            print("âŒ æœªè·å–åˆ°æ–‡ç« ï¼Œè·³è¿‡æ­¤å…¬ä¼—å·")
            continue

        # 2. å…³é”®è¯ç­›é€‰
        filtered_articles = filter_by_keywords(articles, test_account['keywords'])

        if not filtered_articles:
            print("âŒ ç­›é€‰åæ— åŒ¹é…æ–‡ç« ï¼Œè·³è¿‡æ­¤å…¬ä¼—å·")
            continue

        print(f"ğŸ” ç­›é€‰ç»“æœ: {len(articles)} â†’ {len(filtered_articles)} ç¯‡")

        # 3. æ¯ä¸ªå…¬ä¼—å·åªå–å‰2ç¯‡
        selected_articles = filtered_articles[:2]
        print(f"ğŸ“‹ é€‰æ‹©æ–‡ç« : {len(selected_articles)} ç¯‡")

        # 4. ç”ŸæˆAIæ‘˜è¦
        for article in selected_articles:
            ai_summary = generate_ai_summary(article['summary'], article['title'])
            article['ai_summary'] = ai_summary

        all_filtered_articles.extend(selected_articles)

    # 5. æ¨é€æ‰€æœ‰æ–‡ç« åˆ°é£ä¹¦
    if all_filtered_articles:
        print(f"\nğŸ“± å‡†å¤‡æ¨é€æ€»å…± {len(all_filtered_articles)} ç¯‡æ–‡ç« åˆ°é£ä¹¦...")
        success = send_to_feishu(all_filtered_articles)

        if success:
            print("ğŸ‰ çœŸå®æ–‡ç« æ¨é€æˆåŠŸï¼è¯·æ£€æŸ¥æ‚¨çš„é£ä¹¦ç¾¤ç»„ã€‚")
        else:
            print("âŒ æ¨é€å¤±è´¥")
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…çš„æ–‡ç« ")

if __name__ == "__main__":
    main()
